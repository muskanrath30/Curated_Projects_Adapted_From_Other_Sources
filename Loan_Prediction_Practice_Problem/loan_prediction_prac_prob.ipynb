{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Additional imports for new changes\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import joblib  # For saving the model\n",
    "\n",
    "# Reading data\n",
    "train = pd.read_csv('Train_file.csv')\n",
    "test = pd.read_csv('Test_file.csv')\n",
    "\n",
    "# Copy of train and test data so even if we have to make any changes in these datasets\n",
    "# we would not lose the original datasets\n",
    "train_original = train.copy()\n",
    "test_original = test.copy()\n",
    "\n",
    "# Features present in the data and their data types\n",
    "train.columns\n",
    "\n",
    "# Features present in the test dataset\n",
    "test.columns\n",
    "\n",
    "train.dtypes\n",
    "\n",
    "# shape of the dataset\n",
    "train.shape, test.shape\n",
    "\n",
    "train['Loan_Status'].value_counts()\n",
    "\n",
    "# Normalize can be set to true to print proportions\n",
    "# instead of number\n",
    "train['Loan_Status'].value_counts(normalize=True)\n",
    "\n",
    "# Normalize can be set to True to print proportions instead of number\n",
    "train['Loan_Status'].value_counts().plot.bar()\n",
    "\n",
    "# Independent variable (categorical)\n",
    "plt.figure(1, figsize= (20,15))\n",
    "plt.subplot(221)\n",
    "train['Gender'].value_counts(normalize=True).plot.bar(figsize = (20,10),title = 'Gender')\n",
    "plt.subplot(222)\n",
    "train['Married'].value_counts(normalize=True).plot.bar(figsize = (20,10),title = 'Married')\n",
    "plt.subplot(223)\n",
    "train['Self_Employed'].value_counts(normalize=True).plot.bar(title = 'Self_Employed')\n",
    "plt.subplot(224)\n",
    "train['Credit_History'].value_counts(normalize=True).plot.bar(title='Credit_History')\n",
    "plt.show()\n",
    "\n",
    "# Independent Variable (ordinal)\n",
    "plt.figure(1)\n",
    "plt.subplot(131)\n",
    "train['Dependents'].value_counts(normalize=True).plot.bar(figsize=(24,6), title = 'Dependents')\n",
    "plt.subplot(132)\n",
    "train['Education'].value_counts(normalize=True).plot.bar(title='Education')\n",
    "plt.subplot(133)\n",
    "train['Property_Area'].value_counts(normalize=True).plot.bar(title='Property_Area')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(train['ApplicantIncome'])\n",
    "plt.subplot(122)\n",
    "train['ApplicantIncome'].plot.box(figsize=(16,5))\n",
    "plt.show()\n",
    "\n",
    "train.boxplot(column = 'ApplicantIncome', by='Education')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Co-applicant Income Distribution\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(train['CoapplicantIncome'])\n",
    "plt.subplot(122)\n",
    "train['CoapplicantIncome'].plot.box(figsize=(16,5))\n",
    "plt.show()\n",
    "\n",
    "# Distribution of LoanAmount variable\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "df = train.dropna()\n",
    "sns.distplot(train['LoanAmount'])\n",
    "plt.subplot(122)\n",
    "train['LoanAmount'].plot.box(figsize=(16,5))\n",
    "plt.show()\n",
    "\n",
    "# Find the relation between target variable and categorical independent variable\n",
    "Gender = pd.crosstab(train['Gender'], train['Loan_Status'])\n",
    "Gender.div(Gender.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True, figsize=(4,4))\n",
    "\n",
    "# Visualizing remaining categorical vs target variable\n",
    "Married = pd.crosstab(train['Married'], train['Loan_Status'])\n",
    "Dependents = pd.crosstab(train['Dependents'], train['Loan_Status'])\n",
    "Education = pd.crosstab(train['Education'], train['Loan_Status'])\n",
    "Self_Employed = pd.crosstab(train['Self_Employed'], train['Loan_Status'])\n",
    "\n",
    "Married.div(Married.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True, figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Dependents.div(Dependents.sum(1).astype(float), axis =0).plot(kind='bar', stacked = True)\n",
    "plt.show()\n",
    "\n",
    "Education.div(Education.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True, figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Self_Employed.div(Self_Employed.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True, figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "# Relationship between remaining categorical and independent variables and Loan_Status\n",
    "Credit_History = pd.crosstab(train['Credit_History'], train['Loan_Status'])\n",
    "Property_Area = pd.crosstab(train['Property_Area'], train['Loan_Status'])\n",
    "\n",
    "Credit_History.div(Credit_History.sum(1).astype(float), axis=0).plot(kind='bar', stacked = True, figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Property_Area.div(Property_Area.sum(1).astype(float), axis=0).plot(kind='bar', stacked = True)\n",
    "plt.show()\n",
    "\n",
    "# Trying to find out the mean income of people for which loan has been approved\n",
    "# vs the mean income of people for which loan has not been approved\n",
    "train.groupby('Loan_Status')['ApplicantIncome'].mean().plot.bar()\n",
    "\n",
    "bins = [0,2500,4000,6000,81000]\n",
    "group = ['Low','Average', 'High','Very high']\n",
    "train['Income_bin'] = pd.cut(train['ApplicantIncome'], bins, labels=group)\n",
    "Income_bin = pd.crosstab(train['Income_bin'], train['Loan_Status'])\n",
    "Income_bin.div(Income_bin.sum(1).astype(float), axis=0).plot(kind='bar', stacked= True)\n",
    "plt.xlabel('ApplicantIncome')\n",
    "P = plt.ylabel('Percentage')\n",
    "\n",
    "bins = [0,1000,3000, 42000]\n",
    "group = ['Low', 'Average', 'High']\n",
    "train['Coapplicant_Income_bin'] = pd.cut(train['CoapplicantIncome'], bins, labels = group)\n",
    "Coapplicant_Income_bin = pd.crosstab(train['Coapplicant_Income_bin'], train['Loan_Status'])\n",
    "Coapplicant_Income_bin.div(Coapplicant_Income_bin.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.xlabel('CoapplicantIncome')\n",
    "P = plt.ylabel('Percentage')\n",
    "\n",
    "train['Total_Income'] = train['ApplicantIncome'] + train['CoapplicantIncome']\n",
    "bins = [0,2500,4000,6000,81000]\n",
    "group = ['Low', 'Average', 'High','Very High']\n",
    "train['Total_Income_bin'] = pd.cut(train['Total_Income'], bins, labels=group)\n",
    "Total_Income_bin = pd.crosstab(train['Total_Income_bin'], train['Loan_Status'])\n",
    "Total_Income_bin.div(Total_Income_bin.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Total_Income')\n",
    "P = plt.ylabel('Percentage')\n",
    "\n",
    "# Loan Amount Variable\n",
    "bins = [0,100,200,700]\n",
    "group = ['Low','Average','High']\n",
    "train['LoanAmount_bin'] = pd.cut(train['LoanAmount'], bins, labels=group)\n",
    "LoanAmount_bin = pd.crosstab(train['LoanAmount_bin'], train['Loan_Status'])\n",
    "LoanAmount_bin.div(LoanAmount_bin.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.xlabel('LoanAmount')\n",
    "P = plt.ylabel('Percentage')\n",
    "\n",
    "# Lets drop the bins which we created for the exploration part.\n",
    "train=train.drop(['Income_bin','Coapplicant_Income_bin','LoanAmount_bin','Total_Income_bin','Total_Income'], axis=1)\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_train = train.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Compute correlation matrix\n",
    "matrix = numeric_train.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(matrix, vmax=0.8, square=True, cmap=\"BuPu\")\n",
    "plt.show()\n",
    "\n",
    "# CHANGE 3: Independent vs independent variable visualizations (feature vs feature)\n",
    "# Scatter plot: ApplicantIncome vs CoapplicantIncome\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=train, x='ApplicantIncome', y='CoapplicantIncome', hue='Loan_Status')\n",
    "plt.title('Applicant Income vs Coapplicant Income')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot: ApplicantIncome vs LoanAmount\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=train, x='ApplicantIncome', y='LoanAmount', hue='Loan_Status')\n",
    "plt.title('Applicant Income vs Loan Amount')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot: LoanAmount by Property_Area\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=train, x='Property_Area', y='LoanAmount', hue='Loan_Status')\n",
    "plt.title('Loan Amount by Property Area')\n",
    "plt.show()\n",
    "\n",
    "# Checking and imputing missing values\n",
    "train.isnull().sum()\n",
    "train['Gender'].fillna(train['Gender'].mode()[0], inplace=True)\n",
    "train['Married'].fillna(train['Married'].mode()[0], inplace=True)\n",
    "train['Dependents'].fillna(train['Dependents'].mode()[0], inplace=True)\n",
    "train['Self_Employed'].fillna(train['Self_Employed'].mode()[0], inplace=True)\n",
    "train['Credit_History'].fillna(train['Credit_History'].mode()[0], inplace=True)\n",
    "train['Loan_Amount_Term'].value_counts()\n",
    "train['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mode()[0], inplace=True)\n",
    "train['LoanAmount'].fillna(train['LoanAmount'].median(), inplace=True)\n",
    "train.isnull().sum()\n",
    "\n",
    "test['Gender'].fillna(train['Gender'].mode()[0], inplace=True)\n",
    "test['Dependents'].fillna(train['Dependents'].mode()[0], inplace=True)\n",
    "test['Self_Employed'].fillna(train['Self_Employed'].mode()[0], inplace=True)\n",
    "test['Credit_History'].fillna(train['Credit_History'].mode()[0], inplace=True)\n",
    "test['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mode()[0], inplace=True)\n",
    "test['LoanAmount'].fillna(train['LoanAmount'].median(), inplace=True)\n",
    "\n",
    "# CHANGE 2: Combine applicants with 1,2,3 or more dependents into a new feature\n",
    "# Replace '3+' with 3 and convert to int\n",
    "train['Dependents'].replace('3+', 3, inplace=True)\n",
    "test['Dependents'].replace('3+', 3, inplace=True)\n",
    "train['Dependents'] = train['Dependents'].astype(int)\n",
    "test['Dependents'] = test['Dependents'].astype(int)\n",
    "\n",
    "# Create Has_Multiple_Dependents: 1 if Dependents > 0, else 0\n",
    "train['Has_Multiple_Dependents'] = (train['Dependents'] > 0).astype(int)\n",
    "test['Has_Multiple_Dependents'] = (test['Dependents'] > 0).astype(int)\n",
    "\n",
    "# Plot the new feature vs Loan_Status\n",
    "Has_Dep = pd.crosstab(train['Has_Multiple_Dependents'], train['Loan_Status'])\n",
    "Has_Dep.div(Has_Dep.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True, figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "# Visualizing effect of log transformation (similar changes to be done to the test file)\n",
    "train['LoanAmount_log'] = np.log(train['LoanAmount'])\n",
    "train['LoanAmount_log'].hist(bins=20)\n",
    "test['LoanAmount_log'] = np.log(test['LoanAmount'])\n",
    "\n",
    "# Add Total_Income and log\n",
    "train['Total_Income'] = train['ApplicantIncome'] + train['CoapplicantIncome']\n",
    "test['Total_Income'] = test['ApplicantIncome'] + test['CoapplicantIncome']\n",
    "\n",
    "# Let's check the distribution of Total Income\n",
    "sns.distplot(train['Total_Income'])\n",
    "\n",
    "# Take the log transformation to make the distribution normal\n",
    "train['Total_Income_log'] = np.log(train['Total_Income'])\n",
    "sns.distplot(train['Total_Income_log'])\n",
    "test['Total_Income_log'] = np.log(test['Total_Income'])\n",
    "\n",
    "# CHANGE 4: Better EMI formula including interest rates\n",
    "# Assume a fixed average interest rate for personal loans in India, e.g., 10% per annum (0.10 / 12 monthly)\n",
    "# EMI = P * r * (1+r)^n / ((1+r)^n - 1), where P=LoanAmount, r=monthly rate, n=Loan_Amount_Term (months)\n",
    "interest_rate_annual = 0.10  # 10% assumed\n",
    "r = interest_rate_annual / 12  # monthly rate\n",
    "train['EMI_improved'] = train['LoanAmount'] * r * ( (1 + r)**train['Loan_Amount_Term'] ) / ( (1 + r)**train['Loan_Amount_Term'] - 1 )\n",
    "test['EMI_improved'] = test['LoanAmount'] * r * ( (1 + r)**test['Loan_Amount_Term'] ) / ( (1 + r)**test['Loan_Amount_Term'] - 1 )\n",
    "\n",
    "# Plot distribution\n",
    "sns.distplot(train['EMI_improved'])\n",
    "plt.title('Improved EMI Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Balance Income feature now and check its distribution (using improved EMI)\n",
    "# Assuming Total_Income is monthly, and EMI is monthly, no *1000 needed; adjust if units differ\n",
    "train['Balance_Income_improved'] = train['Total_Income'] - train['EMI_improved']\n",
    "test['Balance_Income_improved'] = test['Total_Income'] - test['EMI_improved']\n",
    "sns.distplot(train['Balance_Income_improved'])\n",
    "plt.title('Improved Balance Income Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Replace Loan_Status to numeric\n",
    "train['Loan_Status'].replace('N',0,inplace=True)\n",
    "train['Loan_Status'].replace('Y',1,inplace=True)\n",
    "\n",
    "# Drop Loan_ID\n",
    "train = train.drop('Loan_ID', axis=1)\n",
    "test = test.drop('Loan_ID',axis=1)\n",
    "\n",
    "# Get dummies on features only\n",
    "X = pd.get_dummies(train.drop('Loan_Status', axis=1))\n",
    "y = train['Loan_Status']\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# Making sure the train and test have same columns\n",
    "test = test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Drop original features after engineering\n",
    "drop_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "X = X.drop(columns=[col for col in drop_cols if col in X.columns], errors='ignore')\n",
    "test = test.drop(columns=[col for col in drop_cols if col in test.columns], errors='ignore')\n",
    "\n",
    "# Train test split for some models\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=1, solver='liblinear',tol=0.0001, verbose=0, warm_start=False)\n",
    "model.fit(X_train, y_train)\n",
    "pred_cv = model.predict(X_cv)\n",
    "accuracy_score(y_cv, pred_cv)\n",
    "\n",
    "pred_test = model.predict(test)\n",
    "\n",
    "submission = pd.read_csv('Sample_Submission.csv')\n",
    "submission['Loan_Status'] = pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission['Loan_Status'].replace(0,'N',inplace=True)\n",
    "submission['Loan_Status'].replace(1, 'Y', inplace=True)\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('logistic.csv')\n",
    "\n",
    "# Cross validation logistic\n",
    "i = 1\n",
    "kf = StratifiedKFold(n_splits = 5, random_state = 1, shuffle = True)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} kfold {}'.format(i, kf.n_splits))\n",
    "    xtr, xvl = X.iloc[train_index], X.iloc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = LogisticRegression(random_state=1)\n",
    "    model.fit(xtr, ytr)\n",
    "    pred_test = model.predict(xvl)\n",
    "    score = accuracy_score(yvl, pred_test)\n",
    "    print('Accuracy Score', score)\n",
    "    i += 1\n",
    "    pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:,1]\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(yvl, pred)\n",
    "auc = metrics.roc_auc_score(yvl, pred)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(fpr, tpr, label='validation, auc='+ str(auc))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "submission['Loan_Status'] = pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission['Loan_Status'].replace(0, 'N', inplace=True)\n",
    "submission['Loan_Status'].replace(1, 'Y', inplace=True)\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Logistic.csv')\n",
    "\n",
    "# Logistic with new features (already included since features added before)\n",
    "i = 1\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = LogisticRegression(random_state=1)\n",
    "    model.fit(xtr, ytr)\n",
    "    pred_test = model.predict(xvl)\n",
    "    score = accuracy_score(yvl, pred_test)\n",
    "    print('accuracy_score', score)\n",
    "    i += 1\n",
    "    pred_test = model.predict(test)\n",
    "    pred = model.predict_proba(xvl)[:,1]\n",
    "\n",
    "submission['Loan_Status'] = pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Log2.csv')\n",
    "\n",
    "# Decision Tree\n",
    "i = 1\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = DecisionTreeClassifier(random_state=1)\n",
    "    model.fit(xtr, ytr)\n",
    "    pred_test = model.predict(xvl)\n",
    "    score = accuracy_score(yvl, pred_test)\n",
    "    print('accuracy score', score)\n",
    "    i += 1\n",
    "    pred_test = model.predict(test)\n",
    "\n",
    "submission['Loan_Status'] = pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission['Loan_Status'].replace(0, 'N', inplace=True)\n",
    "submission['Loan_Status'].replace(1, 'Y', inplace=True)\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Decision Tree.csv')\n",
    "\n",
    "# Random Forest\n",
    "i = 1\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = RandomForestClassifier(random_state=1, max_depth=10)\n",
    "    model.fit(xtr, ytr)\n",
    "    pred_test = model.predict(xvl)\n",
    "    score = accuracy_score(yvl, pred_test)\n",
    "    print('accuracy_score', score)\n",
    "    i += 1\n",
    "    pred_test = model.predict(test)\n",
    "\n",
    "paramgrid = {'max_depth': list(range(1,20,2)), 'n_estimators': list(range(1,200,20))}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=1), paramgrid)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_estimator_\n",
    "\n",
    "i = 1\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1,shuffle=True)\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = RandomForestClassifier(random_state=1, max_depth = 5, n_estimators=41)\n",
    "    model.fit(xtr, ytr)\n",
    "    pred_test = model.predict(xvl)\n",
    "    score = accuracy_score(yvl, pred_test)\n",
    "    print('accuracy_score', score)\n",
    "    i += 1\n",
    "    pred_test = model.predict(test)\n",
    "    pred2 = model.predict_proba(test)[:,1]\n",
    "\n",
    "submission['Loan_Status'] = pred_test\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission['Loan_Status'].replace(0, 'N', inplace=True)\n",
    "submission['Loan_Status'].replace(1, 'Y', inplace=True)\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Random Forest.csv')\n",
    "\n",
    "# Feature importances\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "importances.plot(kind='barh', figsize=(12, 8))\n",
    "\n",
    "# CHANGE 1: XGBoost with GridSearchCV\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    XGBClassifier(random_state=1, eval_metric='logloss'),\n",
    "    xgb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(\"Best XGBoost params:\", xgb_grid.best_params_)\n",
    "\n",
    "i = 1\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "xgb_preds = np.zeros(len(test))\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold {}'.format(i, kf.n_splits))\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = XGBClassifier(**xgb_grid.best_params_, random_state=1)\n",
    "    model.fit(xtr, ytr)\n",
    "    pred_test = model.predict(xvl)\n",
    "    score = accuracy_score(yvl, pred_test)\n",
    "    print('accuracy_score', score)\n",
    "    i += 1\n",
    "    fold_pred = model.predict(test)\n",
    "    xgb_preds += fold_pred / 5\n",
    "\n",
    "pred3 = np.round(xgb_preds).astype(int)\n",
    "\n",
    "submission['Loan_Status'] = pred3\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission['Loan_Status'].replace(0,'N',inplace=True)\n",
    "submission['Loan_Status'].replace(1,'Y', inplace = True)\n",
    "pd.DataFrame(submission, columns = ['Loan_ID', 'Loan_Status']).to_csv('XGBoost_Tuned.csv')\n",
    "\n",
    "# CHANGE 5: Ensemble modeling\n",
    "log_reg = LogisticRegression(random_state=1)\n",
    "rf = RandomForestClassifier(random_state=1, max_depth=5, n_estimators=41)\n",
    "xgb = XGBClassifier(**xgb_grid.best_params_, random_state=1)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('lr', log_reg), ('rf', rf), ('xgb', xgb)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "i = 1\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "ensemble_preds = np.zeros(len(test))\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print('\\n{} of kfold for Ensemble {}'.format(i, kf.n_splits))\n",
    "    xtr, xvl = X.loc[train_index], X.loc[test_index]\n",
    "    ytr, yvl = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = ensemble\n",
    "    model.fit(xtr, ytr)\n",
    "    pred_test = model.predict(xvl)\n",
    "    score = accuracy_score(yvl, pred_test)\n",
    "    print('ensemble accuracy_score', score)\n",
    "    i += 1\n",
    "    fold_pred = model.predict(test)\n",
    "    ensemble_preds += fold_pred / 5\n",
    "\n",
    "final_ensemble_pred = np.round(ensemble_preds).astype(int)\n",
    "\n",
    "submission['Loan_Status'] = final_ensemble_pred\n",
    "submission['Loan_ID'] = test_original['Loan_ID']\n",
    "submission['Loan_Status'].replace(0, 'N', inplace=True)\n",
    "submission['Loan_Status'].replace(1, 'Y', inplace=True)\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Ensemble_Voting.csv')\n",
    "\n",
    "# Stacking\n",
    "estimators = [('lr', log_reg), ('rf', rf), ('xgb', xgb)]\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(random_state=1))\n",
    "stacking.fit(X_train, y_train)\n",
    "stack_pred = stacking.predict(test)\n",
    "submission['Loan_Status'] = stack_pred\n",
    "submission['Loan_Status'].replace(0, 'N', inplace=True)\n",
    "submission['Loan_Status'].replace(1, 'Y', inplace=True)\n",
    "pd.DataFrame(submission, columns=['Loan_ID', 'Loan_Status']).to_csv('Stacking_Ensemble.csv')\n",
    "\n",
    "# Save the final stacking model for deployment\n",
    "joblib.dump(stacking, 'loan_prediction_model.pkl')\n",
    "print(\"Model saved as 'loan_prediction_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
